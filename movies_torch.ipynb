{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d8036c4-5a50-4e51-969c-63ec99cfa9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e3401103-074a-4f9e-b770-6a0ceac2659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieReviews(Dataset):\n",
    "    def __init__(self, root_dir, train=True, transform=None):\n",
    "        self.train = train \n",
    "        self.root = root_dir\n",
    "        self.path = self.train_file if self.train else self.test_file\n",
    "        self.reviews = pd.read_csv(self.path, sep=\"\\t\")\n",
    "        self.transform = transform\n",
    "    \n",
    "    @property\n",
    "    def test_file(self):\n",
    "        return os.path.join(self.root, \"test.tsv\")\n",
    "    \n",
    "    @property\n",
    "    def train_file(self):\n",
    "        return os.path.join(self.root, \"train.tsv\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        phrase = self.reviews.iloc[idx, 2]\n",
    "        if self.transform:\n",
    "            phrase = self.transform(phrase)\n",
    "        \n",
    "        if self.train:\n",
    "            y = self.reviews.iloc[idx, 3]\n",
    "            return phrase, y\n",
    "        else:\n",
    "            return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f49e3ed-0848-4a44-bf45-71fe906bc2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_train = MovieReviews(\"./movie_reviews/\", train=True, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "84e2c673-d389-48f3-8cf7-0ca9d8904f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_test = MovieReviews(\"./movie_reviews/\", train=False, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0da48fb6-a351-4e2e-a7ab-fe38141d6d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./movie_reviews/train.tsv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_train.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e5296f9-07b3-4a97-b488-787d3791f846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .',\n",
       " 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46c8a6cc-0f1a-4cbd-8652-ffbdbc0a63d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import ngrams_iterator\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.vocab import Vocab \n",
    "import torchtext\n",
    "from torchtext.data import get_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "426d5970-fa68-4c5c-b541-9ed6fd426fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83075765-1da7-4a25-bc2b-6ea9276bd7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156060lines [00:14, 11023.52lines/s]\n"
     ]
    }
   ],
   "source": [
    "def yield_tokens(data_iter):\n",
    "    for text, _ in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(movie_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5856253c-e5e8-43f8-8b1c-74c02e05576f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.vocab.Vocab at 0x26ea378afc8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6064c81-abd6-40e9-b496-1494991a4a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[201, 12, 20, 1788]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.lookup_indices(['here', 'is', 'an', 'example'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83923d85-b55b-4f3d-8b42-7200cfe710f2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Vocab in module torchtext.vocab object:\n",
      "\n",
      "class Vocab(builtins.object)\n",
      " |  Vocab(counter, max_size=None, min_freq=1, specials=('<unk>', '<pad>'), vectors=None, unk_init=None, vectors_cache=None, specials_first=True)\n",
      " |  \n",
      " |  Defines a vocabulary object that will be used to numericalize a field.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      freqs: A collections.Counter object holding the frequencies of tokens\n",
      " |          in the data used to build the Vocab.\n",
      " |      stoi: A collections.defaultdict instance mapping token strings to\n",
      " |          numerical identifiers.\n",
      " |      itos: A list of token strings indexed by their numerical identifiers.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __getitem__(self, token)\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __init__(self, counter, max_size=None, min_freq=1, specials=('<unk>', '<pad>'), vectors=None, unk_init=None, vectors_cache=None, specials_first=True)\n",
      " |      Create a Vocab object from a collections.Counter.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          counter: collections.Counter object holding the frequencies of\n",
      " |              each value found in the data.\n",
      " |          max_size: The maximum size of the vocabulary, or None for no\n",
      " |              maximum. Default: None.\n",
      " |          min_freq: The minimum frequency needed to include a token in the\n",
      " |              vocabulary. Values less than 1 will be set to 1. Default: 1.\n",
      " |          specials: The list of special tokens (e.g., padding or eos) that\n",
      " |              will be prepended to the vocabulary. Default: ['<unk'>, '<pad>']\n",
      " |          vectors: One of either the available pretrained vectors\n",
      " |              or custom pretrained vectors (see Vocab.load_vectors);\n",
      " |              or a list of aforementioned vectors\n",
      " |          unk_init (callback): by default, initialize out-of-vocabulary word vectors\n",
      " |              to zero vectors; can be any function that takes in a Tensor and\n",
      " |              returns a Tensor of the same size. Default: 'torch.zeros'\n",
      " |          vectors_cache: directory for cached vectors. Default: '.vector_cache'\n",
      " |          specials_first: Whether to add special tokens into the vocabulary at first.\n",
      " |              If it is False, they are added into the vocabulary at last.\n",
      " |              Default: True.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  extend(self, v, sort=False)\n",
      " |  \n",
      " |  load_vectors(self, vectors, **kwargs)\n",
      " |      Arguments:\n",
      " |          vectors: one of or a list containing instantiations of the\n",
      " |              GloVe, CharNGram, or Vectors classes. Alternatively, one\n",
      " |              of or a list of available pretrained vectors:\n",
      " |      \n",
      " |              charngram.100d\n",
      " |              fasttext.en.300d\n",
      " |              fasttext.simple.300d\n",
      " |              glove.42B.300d\n",
      " |              glove.840B.300d\n",
      " |              glove.twitter.27B.25d\n",
      " |              glove.twitter.27B.50d\n",
      " |              glove.twitter.27B.100d\n",
      " |              glove.twitter.27B.200d\n",
      " |              glove.6B.50d\n",
      " |              glove.6B.100d\n",
      " |              glove.6B.200d\n",
      " |              glove.6B.300d\n",
      " |      \n",
      " |          Remaining keyword arguments: Passed to the constructor of Vectors classes.\n",
      " |  \n",
      " |  lookup_indices(self, tokens)\n",
      " |  \n",
      " |  set_vectors(self, stoi, vectors, dim, unk_init=<method 'zero_' of 'torch._C._TensorBase' objects>)\n",
      " |      Set the vectors for the Vocab instance from a collection of Tensors.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          stoi: A dictionary of string to the index of the associated vector\n",
      " |              in the `vectors` input argument.\n",
      " |          vectors: An indexed iterable (or other structure supporting __getitem__) that\n",
      " |              given an input index, returns a FloatTensor representing the vector\n",
      " |              for the token associated with the index. For example,\n",
      " |              vector[stoi[\"string\"]] should return the vector for \"string\".\n",
      " |          dim: The dimensionality of the vectors.\n",
      " |          unk_init (callback): by default, initialize out-of-vocabulary word vectors\n",
      " |              to zero vectors; can be any function that takes in a Tensor and\n",
      " |              returns a Tensor of the same size. Default: 'torch.zeros'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  UNK = '<unk>'\n",
      " |  \n",
      " |  __hash__ = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cebbad6a-0150-4617-a737-ac9006f0945c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[\"here\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4b3c964-4bbd-4e83-ad1a-24401467d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab.lookup_indices(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a42cab6-1b13-4ca1-bf60-19f128fe0c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_pipeline(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85713b68-f27c-4bbd-94cf-bf82ab246ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[201, 12, 2, 20, 1788]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline('here is the an example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "231dc3ba-2e71-44ca-853f-ad39dfca1b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_text, _label) in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64).to(device)\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64).to(device)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0).to(device)\n",
    "    text_list = torch.cat(text_list).to(device)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c27255d5-ba77-4688-8434-d2ed5aa9356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0720895-9cfc-45f8-87a7-7633d357783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_map = {\n",
    "    0: \"negative\",\n",
    "    1: \"somewhat negative\",\n",
    "    2: \"neutral\",\n",
    "    3: \"somewhat positive\",\n",
    "    4: \"positive\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "674c30c9-fc54-4685-800e-9d48b266fa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(sentiment_map.keys())\n",
    "vocab_size = len(vocab)\n",
    "embed_size = 64\n",
    "model = TextClassificationModel(vocab_size, embed_size, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d09c3012-d2c8-4882-8789-110b793be17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "#     with torch.no_grad():\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predited_label = model(text, offsets)\n",
    "        loss = criterion(predited_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predited_label = model(text, offsets)\n",
    "            loss = criterion(predited_label, label)\n",
    "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f36246f2-16f3-4b9f-9901-bd188d16ab6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "#from torchtext.data.functional import to_map_style_dataset\n",
    "# Hyperparameters\n",
    "EPOCHS = 10 # epoch\n",
    "LR = 5  # learning rate\n",
    "BATCH_SIZE = 64 # batch size for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "592e18e0-5fec-4773-8228-1321b7045f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = int(len(movie_train) * 0.95)\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(movie_train, [num_train, len(movie_train) - num_train])\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3a8f78-0ef2-450d-9e88-3d4d9641fd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cae48bb5-60e9-4d07-aa3d-c76155b197d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device=None):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if not device:\n",
    "        device = _device\n",
    "\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"\n",
    "    Wrap a dataloader to move data to a device\n",
    "    \"\"\"\n",
    "    def __init__(self, dl, device=None):\n",
    "        self.dl = dl\n",
    "        if device:\n",
    "            device = device\n",
    "        else:\n",
    "            device = _device\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        Yield a batch of data after moving it to device\n",
    "        \"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Number of batches\n",
    "        \"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebc81052-a6b9-4abf-8aaf-660015405651",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DeviceDataLoader(train_dataloader, device=device)\n",
    "valid_dataloader = DeviceDataLoader(valid_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe84d7c0-26eb-425e-b3dd-bdf86413a6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5fe76c36-1bee-49c8-a3d5-8ba4a5dc2025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   500/ 2317 batches | accuracy    0.497\n",
      "| epoch   1 |  1000/ 2317 batches | accuracy    0.501\n",
      "| epoch   1 |  1500/ 2317 batches | accuracy    0.510\n",
      "| epoch   1 |  2000/ 2317 batches | accuracy    0.526\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time: 26.13s | valid accuracy    0.532 \n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |   500/ 2317 batches | accuracy    0.545\n",
      "| epoch   2 |  1000/ 2317 batches | accuracy    0.549\n",
      "| epoch   2 |  1500/ 2317 batches | accuracy    0.559\n",
      "| epoch   2 |  2000/ 2317 batches | accuracy    0.559\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time: 25.83s | valid accuracy    0.554 \n",
      "-----------------------------------------------------------\n",
      "| epoch   3 |   500/ 2317 batches | accuracy    0.584\n",
      "| epoch   3 |  1000/ 2317 batches | accuracy    0.585\n",
      "| epoch   3 |  1500/ 2317 batches | accuracy    0.583\n",
      "| epoch   3 |  2000/ 2317 batches | accuracy    0.584\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time: 26.27s | valid accuracy    0.563 \n",
      "-----------------------------------------------------------\n",
      "| epoch   4 |   500/ 2317 batches | accuracy    0.601\n",
      "| epoch   4 |  1000/ 2317 batches | accuracy    0.598\n",
      "| epoch   4 |  1500/ 2317 batches | accuracy    0.600\n",
      "| epoch   4 |  2000/ 2317 batches | accuracy    0.597\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time: 29.84s | valid accuracy    0.571 \n",
      "-----------------------------------------------------------\n",
      "| epoch   5 |   500/ 2317 batches | accuracy    0.613\n",
      "| epoch   5 |  1000/ 2317 batches | accuracy    0.609\n",
      "| epoch   5 |  1500/ 2317 batches | accuracy    0.606\n",
      "| epoch   5 |  2000/ 2317 batches | accuracy    0.609\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time: 27.98s | valid accuracy    0.574 \n",
      "-----------------------------------------------------------\n",
      "| epoch   6 |   500/ 2317 batches | accuracy    0.616\n",
      "| epoch   6 |  1000/ 2317 batches | accuracy    0.621\n",
      "| epoch   6 |  1500/ 2317 batches | accuracy    0.615\n",
      "| epoch   6 |  2000/ 2317 batches | accuracy    0.614\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time: 26.53s | valid accuracy    0.574 \n",
      "-----------------------------------------------------------\n",
      "| epoch   7 |   500/ 2317 batches | accuracy    0.626\n",
      "| epoch   7 |  1000/ 2317 batches | accuracy    0.614\n",
      "| epoch   7 |  1500/ 2317 batches | accuracy    0.616\n",
      "| epoch   7 |  2000/ 2317 batches | accuracy    0.611\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time: 26.18s | valid accuracy    0.578 \n",
      "-----------------------------------------------------------\n",
      "| epoch   8 |   500/ 2317 batches | accuracy    0.627\n",
      "| epoch   8 |  1000/ 2317 batches | accuracy    0.622\n",
      "| epoch   8 |  1500/ 2317 batches | accuracy    0.618\n",
      "| epoch   8 |  2000/ 2317 batches | accuracy    0.615\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time: 28.03s | valid accuracy    0.580 \n",
      "-----------------------------------------------------------\n",
      "| epoch   9 |   500/ 2317 batches | accuracy    0.631\n",
      "| epoch   9 |  1000/ 2317 batches | accuracy    0.624\n",
      "| epoch   9 |  1500/ 2317 batches | accuracy    0.625\n",
      "| epoch   9 |  2000/ 2317 batches | accuracy    0.615\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time: 29.78s | valid accuracy    0.578 \n",
      "-----------------------------------------------------------\n",
      "| epoch  10 |   500/ 2317 batches | accuracy    0.643\n",
      "| epoch  10 |  1000/ 2317 batches | accuracy    0.642\n",
      "| epoch  10 |  1500/ 2317 batches | accuracy    0.642\n",
      "| epoch  10 |  2000/ 2317 batches | accuracy    0.641\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time: 27.26s | valid accuracy    0.585 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab47740-1969-40fc-b631-d1fc73bde6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
